{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función get_all_tweets (Adaptada)\n",
    "##### Adaptación de la función get_all_tweets (seankross) que elimina el problema de la extensión, incluye más variables y a su vez se incluye la versión iterada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión original de la función: https://gist.github.com/seankross/9338551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_key = ''\n",
    "access_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets_adap(screen_name):\n",
    "    #Twitter solo permite extracción de 3240 trinos con este método\n",
    "    \n",
    "    #Datos de Twitter\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #Guardar todos los datos\n",
    "    alltweets = []  \n",
    "    \n",
    "    #Hacer el request\n",
    "    assert (screen_name in [\"nan\", None]), \"Casilla en Blanco\"\n",
    "    \n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200, tweet_mode=\"extended\")\n",
    "    \n",
    "    #Guardar \n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #Guardar los datos\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #Seguir recogiendo datos\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets from {screen_name}\")\n",
    "        \n",
    "        \n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest, tweet_mode='extended')\n",
    "        \n",
    "        #Guardar\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #Guardar\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #Transformar las listas a un dataframe\n",
    "    outtweets=[]\n",
    "    for tweet in alltweets:\n",
    "        if tweet.full_text.startswith(\"RT @\") == True:\n",
    "            try:\n",
    "                outtweets.append([tweet.user.screen_name, tweet.created_at, tweet.retweeted_status.full_text,tweet.user.location, tweet.user.description,tweet.retweet_count,tweet.favorite_count,tweet.in_reply_to_screen_name,tweet.coordinates,tweet.place,True, tweet.retweeted_status.user.screen_name])\n",
    "            except:\n",
    "                outtweets.append([tweet.user.screen_name, tweet.created_at, tweet.full_text,tweet.user.location, tweet.user.description,tweet.retweet_count,tweet.favorite_count,tweet.in_reply_to_screen_name,tweet.coordinates,tweet.place,False,None])\n",
    "        else:\n",
    "            outtweets.append([tweet.user.screen_name, tweet.created_at, tweet.full_text,tweet.user.location, tweet.user.description,tweet.retweet_count,tweet.favorite_count,tweet.in_reply_to_screen_name,tweet.coordinates,tweet.place,False,None])\n",
    "\n",
    "\n",
    "    #Guardar el csv  \n",
    "    with open(f'new_{screen_name}_tweets.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\",\"location\",\"bio\",\"retweets\",\"favourites\",\"in_reply_to_screen_name\", \"coordinates\",\"place\", \"is_retweet\", \"retweeted_account_id\"])\n",
    "        writer.writerows(outtweets)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_tweets_adap(\"\") #Una sola cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establecer un directorio\n",
    "os.chdir(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para varias cuentas\n",
    "for i in nombres:\n",
    "    try:\n",
    "        get_all_tweets_adap(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar todos los archivos en uno solo parte 1\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar todos los archivos en uno solo parte 2\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar todos los archivos en uno solo parte 3\n",
    "combined_csv.to_excel( \"combined.xlsx\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
